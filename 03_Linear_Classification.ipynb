{
 "metadata": {
  "name": "03_Linear_Classification"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<h1>Readings</h1>\n",
      "<ul>\n",
      "    <li>Bishop: 4.2.0-4.2.4, 4.3.0-4.3.4</li>\n",
      "    <li>Ng: Lecture 2 pdf, pages 18 - 26</li>\n",
      "    <li> -----------</li>\n",
      "    <li>Ng: Lecture 2 pdf, page 24 Constructing GLMs</li>\n",
      "    <li>Ng: Lecture 2 pdf, page 26 Logistic Regression</li>\n",
      "    <li>Ng: Lecture 2 pdf, page 18 Bernoulli example</li>\n",
      "    <li>Ng: Lecture 2 pdf, page 19 Using Newton for Bernoulli example</li>\n",
      "    <li>Bishop: 4.3.4</li>\n",
      "    <li>Ng: Lecture 2 pdf, page 26 Softmax Regression</li>\n",
      "</ul>"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<h1>Introduction</h1>\n",
      "This notebook describes several linear models for classification, i.e. given an input vector $\\mathbf{x}$ determine $p(C_k|\\mathbf{x})$ where $k\\in \\\\{1\\ldots K\\\\}$ and $C_k$ is a \n",
      "discrete class label. Note that the algorithms described here can also be applied to transformed input, $\\phi(x)$, to determine $p(C_k|\\phi(\\mathbf{x}))$, where $\\phi$ may \n",
      "be a nonlinear tranformation of the input space. \n",
      "\n",
      "Our **first model assumption** is that our target output can be modeled as <br/>\n",
      "\n",
      "$y(\\phi(\\mathbf{x})) = f(\\mathbf{w}^T\\phi(\\mathbf{x}))$<br/>\n",
      "\n",
      "where $y$ will be a vector of probabilities with $K$ elements. The elements of $y$ are $y_i = p(C_i|\\phi(\\mathbf{x}))$ i.e. the probability that the input vector $\\mathbf{x}$ is in\n",
      "the class $C_i$. Often we will have simply that $\\mathbf{w}^T\\phi(\\mathbf{x}) = \\mathbf{w}^T\\mathbf{x}+w_0$ in which case we will simply omit $\\phi$ from the notation. \n",
      "The function $f$ is known as the **activation function** and its inverse is known as the **link function**. Note that $f$ will often be nonlinear.\n",
      "\n",
      "It should be noted that nearly all of the material presented fails to be a fully Bayesian treatment of the classification problem. Primarily this is because a Bayesian approach \n",
      "to the classification problem is mathematically intractable. However, Bayes' Theorem will appear often in the discussion, which can lead to confusion. Where appropriate, I \n",
      "will try to clarify the difference.\n",
      "\n",
      "Another factor to keep in mind is that the target variable, $y$, described in our model above, does **not provide a decision** for a class assignment for a given input $\\mathbf{x}$. \n",
      "In real world cases where it is necessary to make a decision as to which class $\\mathbf{x}$ should be assigned, one must apply an additional modeling step based on *decision theory*. \n",
      "There are a variety of decision models, all of which leverage the class posterior probability models, $p(C_k|\\mathbf{x})$, such as\n",
      "\n",
      "* Minimizing the misclassification rate - this effectively corresponds to chosing the class with the highest probability for a given $\\mathbf{x}$\n",
      "* Minimizing the expected loss - minimizes the expected value of a given loss function, $L$, under the class posterior probability distribution\n",
      "* Reject option\n",
      "\n",
      "The models presented here are called *linear* because, when the decision criteria is that of minimizing the misclassification rate, they divide the input\n",
      "space into $K$ regions, where the boundaries between regions are linear functions of the input vector $\\mathbf{x}$. The decision boundaries will correspond to where \n",
      "$\\mathbf{w}^T\\mathbf{x}=constant$, and thus represent a linear function of $\\mathbf{x}$. \n",
      "In the case of transformed input, $\\phi(\\mathbf{x})$, the decision boundaries will correspond to where \n",
      "$\\mathbf{w}^T\\phi(\\mathbf{x})=constant$, and thus represent a linear function of $\\phi(\\mathbf{x})$. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<h1>Probabilistic Generative Models</h1>\n",
      "We begin our discussion of linear classifcation with methods that model the activation function with the class posterior probabilities by first modeling the *class-conditional densities*,\n",
      "$p(\\mathbf{x}|C_k$), and the class priors, $p(C_k)$, and then applying Bayes' Theorem. Thus for $K$ classes, our activation function is <br/>\n",
      "\n",
      "$f = p(C_k | \\mathbf{x}) = \\frac{\\exp(a_k)}{\\sum_j \\exp(a_j)}$ <br/>\n",
      "\n",
      "where $a_j = \\ln(p(\\mathbf{x}|C_k)p(C_k))$ In the case of $K=2$, the activation function reduces to the *logistic sigmoid* function <br/><br/>\n",
      "$f = p(C_1|\\mathbf{x}) = \\frac{1}{1+\\exp(-a)} = \\sigma(a)$ <br/><br/>\n",
      "where $a = \\ln \\frac {p(\\mathbf{x}|C_1)p(C_1)} {p(\\mathbf{x}|C_2)p(C_2)}$ <br/>\n",
      "\n",
      "Note that this is **not** a Bayesian model. Nowhere have we modeled the parameter posterior probability $p(\\mathbf{w}|\\mathbf{t})$. Indeed, we will see shortly that we will use a \n",
      "maximum likelihood approach to determine $\\mathbf{w}$.\n",
      "\n",
      "These models are **known as generative models** because they can be used to generate synthetic input\n",
      "data by applying <a href=\"http://en.wikipedia.org/wiki/Inverse_transform_sampling\">Inverse Transform Sampling</a> to the marginal distribution for $\\mathbf{x}$ defined by <br/>\n",
      "\n",
      "$p(\\mathbf{x}) = \\sum_k p(\\mathbf{x}|C_k)p(C_k)$ <br/>\n",
      "\n",
      "To move forward, it is necessary to start making **model assumptions**. Here we will *assume* that we have continuous inputs, i.e. $x\\in \\Re$ *(see Bishop 202 for discrete input)*,and \n",
      "that the *class-conditional densities*,\n",
      "$p(\\mathbf{x}|C_k)$ are modeled by a Gaussian distribution. Under the Gaussian assumption, the class-conditional density  for class $C_k$ is <br/><br/>\n",
      "\n",
      "$p(\\mathbf{x}|C_k) = \\frac{1}{\\left(2 \\pi \\right)^{D/2}} \\frac{1}{|\\mathbf{\\Sigma}|^{1/2}} \\exp \\\\{ -\\frac{1}{2} (\\mathbf{x} - \\mathbf{\\mu}_k)^T \\mathbf{\\Sigma}^{-1} (\\mathbf{x} - \\mathbf{\\mu}_k) \\\\}$ <br/><br/>\n",
      "\n",
      "where $D$ is the dimension of the input vector $\\mathbf{x}$, $\\mathbf{\\Sigma}$ is the *covariance matrix* and $\\mathbf{\\mu}$ is the mean vector and where we have *assumed* that all classes share the same covariance matrix. \n",
      "\n",
      "In the case of two classes, this result is substituted into the logistic sigmoid function and reduces to <br/><br/>\n",
      "\n",
      "$p(C_1|\\mathbf{x}) = \\sigma \\left( \\mathbf{w}^T \\mathbf{x} + w_0 \\right)$ <br/><br/>\n",
      "\n",
      "were we have defined <br/><br/>\n",
      "\n",
      "$\\mathbf{w} = \\mathbf{\\Sigma}^{-1} \\left( \\mathbf{\\mu}_1 - \\mathbf{\\mu}_2 \\right)$ <br/><br/>\n",
      "\n",
      "$w_0 = -\\frac{1}{2} \\mathbf{\\mu}_1^T \\mathbf{\\Sigma}^{-1} \\mathbf{\\mu}_1 + \\frac{1}{2} \\mathbf{\\mu}_2^T \\mathbf{\\Sigma}^{-1} \\mathbf{\\mu}_2 + \\ln \\frac{p(C_1)} {p(C_2)}$ <br/><br/>\n",
      "\n",
      "Notice that the class prior probabilities, $p(C_k)$, effectively act as a bias term. Also note, that we have yet to specify a model for these distributions. If we are to use the result above,\n",
      "we will need to make **another model assumption**. Here we will *assume* that the *class priors* are modeled by a Bernoulli distribution with $p(C_1)=\\gamma$ and $p(C_2)=1-\\gamma$. In the case of $K>2$ classes\n",
      "we obtain <br/><br/>\n",
      "\n",
      "$a_k(\\mathbf{x}) = \\left[\\mathbf{\\Sigma}^{-1} \\mathbf{\\mu}_k \\right]^T \\mathbf{x} - \\frac{1}{2} \\mathbf{\\mu}_k^T \\mathbf{\\Sigma}^{-1} \\mathbf{\\mu}_k + \\ln p(C_k)$ <br/><br/>\n",
      "\n",
      "Note that we still have not formulated a complete model for the posterior class densities, in that we have not yet solved for the model parameters, $\\mathbf{\\mu}$ and $\\mathbf{\\Sigma}$. We do that\n",
      "now using a **maximum likelihood** approach.\n",
      "\n",
      "<h2>Maximum Likelihood Solution</h2>\n",
      "Considering the case of two classes, $C_1$ and $C_2$, with Bernoulli prior distributions, $p(C_1)=\\pi$ and $p(C_2)=1-\\pi$, and with Gaussian *class-conditional density* distributions\n",
      "$p(\\mathbf{x}|C_k)$, assume we have a training data set, $\\mathbf{X}$, with $N$ elements of the form $\\\\{\\mathbf{x}_n, t_n\\\\}$ where $t_n=0$ indicates that $\\mathbf{x_n}$ is in class $C_1$ and $t_n=1$\n",
      "indicates that $\\mathbf{x_n}$ is in class $C_2$. The likelihood function is then given by <br/><br/>\n",
      "\n",
      "$p(\\mathbf{t}, \\mathbf{X} | \\pi, \\mathbf{\\mu}_1, \\mu_2, \\mathbf{\\Sigma}) = \\prod_{n=1}^N \\left[\\pi ND(\\mathbf{x}_n | \\mu_1, \\mathbf{\\Sigma})\\right]^{t_n} \\left[(1-\\pi) ND(\\mathbf{x}_n | \\mu_2, \\mathbf{\\Sigma})\\right]^{1-t_n}$ <br/><br/>\n",
      "\n",
      "Taking the derivate of this expression with respect to the various model parameters, $\\pi$, $\\mu_1$, $\\mu_2$, and $\\mathbf{\\Sigma}$, and setting it equal to zero, we obtain the following\n",
      "estimates <br/><br/>\n",
      "\n",
      "$\\pi = \\frac{N_1}{N_1+N_2}$ <br/><br/>\n",
      "where $N_1$ is the number of training inputs in class $C_1$ and $N_2$ is the number in class $C_2$. <br/><br/>\n",
      "\n",
      "$\\mu_1 = \\frac{1}{N_1} \\sum_{n=1}^N t_n \\mathbf{x_n}$ <br/><br/>\n",
      "\n",
      "$\\mu_2 = \\frac{1}{N_2} \\sum_{n=1}^N (1-t_n) \\mathbf{x_n}$ <br/><br/>\n",
      "\n",
      "$\\mathbf{\\Sigma} = \\frac{1}{N}\\left[ \\sum_{n\\in C_1} (\\mathbf{x_n}-\\mu_1)(\\mathbf{x_n}-\\mu_1)^T + \\sum_{n\\in C_2} (\\mathbf{x_n}-\\mu_2)(\\mathbf{x_n}-\\mu_2)^T \\right] $ <br/><br/>\n",
      "\n",
      "<h2>Example 1</h2>\n",
      "Let's begin by generating artificial data. Let's assume we have 1-D input. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "import math\n",
      "from matplotlib import pyplot as plt\n",
      "import scipy.integrate as sciInt\n",
      "import scipy.optimize as sciOpt\n",
      "\n",
      "#select truth data values, these will NOT be known to the training algorithm, they\n",
      "#are only used in generating the sample data\n",
      "tu1 =-2.0\n",
      "tu2 = 2.0\n",
      "tSigma = 2.\n",
      "tGamma = 0.5\n",
      "\n",
      "#the class conditional probability p(x|Ck)\n",
      "def p_xCk(x, mu, sigma):\n",
      "    denom = math.sqrt(2.0 * math.pi * sigma)\n",
      "    arg = -0.5 * (x - mu) * (x - mu) / sigma\n",
      "    return math.exp(arg) / denom\n",
      "\n",
      "#the marginal probability p(x)\n",
      "def p_x(x, mu1, mu2, sigma, gamma):\n",
      "    return gamma * p_xCk(x, mu1, sigma) + (1.0 - gamma) * p_xCk(x, mu2, sigma)\n",
      "\n",
      "#posterior class probability vector (p(C_1|x), p(C_2|x))\n",
      "def p_Ckx(x, mu1, mu2, sigma, gamma):\n",
      "    a = math.log(p_xCk(x, mu1, sigma)*gamma/(p_xCk(x,mu2,sigma)*(1-gamma)))\n",
      "    pc1 = 1.0/(1.0 + math.exp(-a))\n",
      "    return (pc1, 1.0 - pc1)\n",
      "\n",
      "domain = range(0,100,1)\n",
      "domain = [(-5.0 + x/10.0) for x in domain]\n",
      "f, axarr = plt.subplots(2,2)\n",
      "\n",
      "#plot p(x|Ck)\n",
      "pxC1 = [p_xCk(x,tu1,tSigma) for x in domain]\n",
      "pxC2 = [p_xCk(x,tu2,tSigma) for x in domain]\n",
      "ax1 = axarr[0,0]\n",
      "ax1.plot(domain, pxC1)\n",
      "ax1.plot(domain, pxC2)\n",
      "\n",
      "#plot the marginal distribution p(x)\n",
      "px = [p_x(x, tu1, tu2, tSigma, tGamma) for x in domain]\n",
      "ax2 = axarr[0,1]\n",
      "ax2.plot(domain,px)\n",
      "\n",
      "#plot the posterior distributions p(C_1|x) & p(C_2|x)\n",
      "pc1x = []\n",
      "pc2x = []\n",
      "for x in domain:\n",
      "    pck = p_Ckx(x, tu1, tu2, tSigma, tGamma)\n",
      "    pc1x.append(pck[0])\n",
      "    pc2x.append(pck[1])\n",
      "ax3 = axarr[1,0]\n",
      "ax3.plot(domain, pc1x)\n",
      "ax3.plot(domain, pc2x)\n",
      "\n",
      "#the cumulative distribution function P(x<X)\n",
      "def cdf(x, mu1, mu2, sigma, gamma):\n",
      "    return sciInt.quad(func=p_x, a=-np.inf, b=x, args=(mu1, mu2, sigma, gamma))\n",
      "\n",
      "#inverse of the CDF\n",
      "def inv_cdf(y, mu1, mu2, sigma, gamma):\n",
      "    def f(x):\n",
      "        return cdf(x,mu1,mu2,sigma,gamma)[0] - y\n",
      "    return sciOpt.newton(f, 0)\n",
      "\n",
      "#lets check our inv_cdf func, if its correct, domain and cdfs should be the same\n",
      "#domain = [x/10.0 for x in range(12)[1:11]]\n",
      "#icdfs = [inv_cdf(x, tu1, tu2, tSigma, tGamma) for x in domain]\n",
      "#cdfs = [cdf(x, tu1, tu2, tSigma, tGamma)[0] for x in icdfs]\n",
      "#print domain\n",
      "#print icdfs\n",
      "#print cdfs\n",
      "#plt.plot(icdfs, cdfs)\n",
      "\n",
      "seed = 123456789\n",
      "np.random.seed(seed)\n",
      "num_samples = 100\n",
      "x = np.zeros(num_samples)\n",
      "t = np.zeros(num_samples)\n",
      "pcx = np.zeros(num_samples)\n",
      "n1 = 0\n",
      "nae = 0\n",
      "assignment_epsilon = 0.5\n",
      "for i in range(num_samples):\n",
      "    rv = np.random.uniform()\n",
      "    x[i] = inv_cdf(rv, tu1, tu2, tSigma, tGamma)\n",
      "    pcx1 = p_Ckx(x[i], tu1, tu2, tSigma, tGamma)\n",
      "    pcx2 = pcx1[1]\n",
      "    pcx1 = pcx1[0]\n",
      "    if math.fabs(pcx2-pcx1) <= assignment_epsilon:\n",
      "        nae = nae + 1\n",
      "        if np.random.uniform() <= 0.5:\n",
      "            t[i] = 0\n",
      "            n1 = n1 + 1\n",
      "        else:\n",
      "            t[i] = 1\n",
      "    elif pcx2 > pcx1:\n",
      "        t[i] = 0\n",
      "        n1 = n1 +1\n",
      "    else: t[i]=1\n",
      "\n",
      "print 'The number of inputs in C1 is {0}'.format(n1)\n",
      "print 'The number of inputs that were assigned based on the assignment factor is {0}'.format(nae)\n",
      "#plot the simulated data\n",
      "ax4 = axarr[1,1]\n",
      "ax4.scatter(x, t)\n",
      "ax4.axvline(0)\n",
      "plt.show()\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "The number of inputs in C1 is 47\n",
        "The number of inputs that were assigned based on the assignment factor is 12\n"
       ]
      },
      {
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAXgAAAD9CAYAAAC2l2x5AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRK5CYII=\n"
      }
     ],
     "prompt_number": 129
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now lets consider a 2-D input case."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "import math\n",
      "#select truth data values, these will NOT be known to the training algorithm, they\n",
      "#are only used in generating the sample data\n",
      "tu1 = np.array(0.25)\n",
      "tu2 = np.array(-0.25)\n",
      "tSigma = np.array(1.0)\n",
      "tGamma = 0.3\n",
      "\n",
      "def p_xCk(x, mu, Sigma):\n",
      "    D = x.size\n",
      "    denom = math.pow(2.0*math.pi, D/2.0) * math.sqrt(np.linalg.det(Sigma))\n",
      "    arg = np.dot((x - mu).T, np.linalg.inv(Sigma))\n",
      "    arg = np.dot(arg, (x - mu))\n",
      "    print arg\n",
      "    arg = math.exp(-0.5 * arg)\n",
      "    return arg / denom\n",
      "    \n",
      "def p_x(x, mu1, mu2, sigma, gamma):\n",
      "    gamma * p_xCk(x, mu1, sigma) + (1.0 - gamma) * p_xCk(x, mu2, sigma)\n",
      "    \n",
      "x = np.array(1.0)\n",
      "#print p_x(x, tu1, tu2, tSigma, tGamma)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<h1>Logistic Regression: Gradient Descent</h1>\n",
      "<font color = \"red\">This should be moved to a Linear Classification Section</font>\n",
      "<p>$\\theta_{j+1} = \\theta_j + \\alpha\\left[y^{(i)} -h\\left(x^{(i)}\\right)\\right]x_j^{(i)}$ <br/><br/>\n",
      "    where $h(x)$ is the <em>sigmoid function</em>\n",
      "</p>"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<h1>Logistic Regression: Newton's Method</h1>\n",
      "<p>\n",
      "    Given $f(\\theta)$ find $\\theta$ s.t. $f(\\theta)=0$ <br/><br/>\n",
      "    $\\Delta = \\frac{f(\\theta^{(t)})}{f'(\\theta^{(t)})}$ <br/><br/>\n",
      "    $\\theta^{(t+1)}=\\theta^{(t)} - \\Delta$ <br/><br/>\n",
      "    Consider now, finding the zero of the derivative of $f(x)$. Then Newton's method becomes: <br/><br/>\n",
      "    $\\theta^{(t+1)}=\\theta^{(t)}-\\frac{f'(\\theta^{(t)})}{f''(\\theta^{(t)})}$ \n",
      "    If the input $x$ is a vector, then Newton's method takes on the general form: <br/><br/>\n",
      "    $\\theta^{(t+1)}=\\theta^{(t)} - H^{-1}\\bigtriangledown_{\\theta} f$ <br/><br/>\n",
      "    where $H$ is the Hessian where <br/><br/>\n",
      "    $H_{i,j}=\\frac{\\partial^2f}{\\partial\\theta_i\\partial\\theta_j}$ <br/><br/>\n",
      "    Note that for large training sets, computing the Hessian matrix at each iteration could be computationally\n",
      "    expensive\n",
      "\n",
      "</p>"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<h1>Exponential Family Distributions</h1>\n",
      "Basically, he covered the section from CH2 of the text"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<h1>Generalized Linear Models (GLM)</h1>\n",
      "Assume\n",
      "1. y|x;theta follows some exponential family distribution with parameter eta\n",
      "2. goal is to output E[T(y)|x] given some x, where T(y) usually is y\n",
      "i.e. want h(x)=E[T(y)|x]\n",
      "3. assume eta = Theta.T x OR eta_i = Theta_i.T x if theta in R^K\n",
      "\n",
      "Bernoulli:\n",
      "For fixed x,theta algorithm outputs \n",
      "h(x) = E[y|x;theta] = P(y=1|x,theta)=phi=1/(1+exp(-eta))=1/(1+exp(-theta.T x))\n",
      "g(eta)=E[y;eta] canonical response function\n",
      "g^{-1} canonical link function\n",
      "\n",
      "Gaussian example - he skipped but it should be covered in the reading\n",
      "\n",
      "(SOFTMAX REGRESSION - the generalization of binary logistic regression to multiple classes) Multinomial example - y in a set of K possible outcomes\n",
      "Parameters are phi_1, ..., phi_k\n",
      "P(y=i) = phi_i\n",
      "but phi_k = 1 -(phi_1 + ... + phi_(k-1)) so drop phi_k\n",
      "T(k) is a col vec of length k-1 where the kth element is 1, others are zero, T(k) is all zeros\n",
      "T(y)_i is the ith element of T(y) and equal to L{y==i} where is the \"indicator\" function, returns true/false based on the input statement, so here\n",
      "T(y)_i is equal to one only if y=i\n",
      "\n",
      "So dist for multi nomial is\n",
      "P(y)=phi_1^{L{y=1}} X ... X phi_k^{L{y=k}}\n",
      "$=phi_1^{T(y)_1}phi_2^{T(y)_2}...phi_{k-1}^{T(y)_{k-1}}phi_k^{1-\\sum_{j=1}^{k-1}T(y)_j}$\n",
      "=simplified to exp fam form (see lect notes)\n",
      "\n",
      "so the learn alg becomes\n",
      "h_theta(x) = E[T(y)|x;theta] see lect notes\n",
      "\n",
      "So how does this work:\n",
      "-Assume you have K outputs\n",
      "-Assume that the distribution is modeled by a multi-nomial distribution\n",
      "-Given a training set (x^{(i)},y^{(i)}), ..., (x^{(m)},y^{(m)})\n",
      "-find model params by maxing likelihood\n",
      "L(theta) = \\prod_{i=1}^m p(y^{(i)}|x^{(i)};theta)\n",
      "=\\prod_i^m \\phi_1^{L(y^{(i)}=1}...\\phi_k^{L(y^{(i)}=k}\n",
      "where phi_1 is given by the exponential function in the lec notes and is dependent on x, theta is in R^{n+1}"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<h2>Generative Algorithms</h2>\n",
      "When to use Generative vs. Discrimentive? A rule of thumb is based on the following: If p(x|y) is exponentially distributed it implies the posterior \n",
      "p(y|x) is logisitic, however the inverse is not true, i.e. a logistic p(y|x) does not imply an exponentially distributed p(x|y). It turns out that if \n",
      "p(x|y) is indeed exponentially distributed then a generative model will perform better. So if for a given modeling problem, there is sufficient reason\n",
      "to believe p(x|y) is exponentially distributed one should attempt a generative model. On the other hand, if this is not known, it is likely that a \n",
      "discriminative model may perform better.\n",
      "\n",
      "<h2>Naive Bayes</h2>\n",
      "y in (0,1)"
     ]
    }
   ],
   "metadata": {}
  }
 ]
}